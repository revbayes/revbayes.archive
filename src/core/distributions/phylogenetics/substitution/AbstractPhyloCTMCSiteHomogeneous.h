#ifndef AbstractPhyloCTMCSiteHomogeneous_H
#define AbstractPhyloCTMCSiteHomogeneous_H

#include "AbstractHomologousDiscreteCharacterData.h"
#include "ConstantNode.h"
#include "DiscreteTaxonData.h"
#include "DnaState.h"
#include "MemberObject.h"
#include "RbMathLogic.h"
#include "RbSettings.h"
#include "RbVector.h"
#include "RateGenerator.h"
#include "TopologyNode.h"
#include "TransitionProbabilityMatrix.h"
#include "Tree.h"
#include "TreeChangeEventListener.h"
#include "TypedDistribution.h"

#include <memory.h>

namespace RevBayesCore {

    /**
     * @brief Homogeneous distribution of character state evolution along a tree class (PhyloCTMC).
     *
     * This file contains the distribution class for a character state evolving along a tree.
     * This abstract base class can be derived for any character evolution model with homogeneous mixture sites. A
     * homogeneous mixture model over sites is a model where all sites are drawn from the same distribution and the
     * specific instance of the per site parameter is integrated over. The per site parameter could be a rate scaler (e.g. the + gamma models)
     * or different rate matrices or anything else.
     *
     * The pruning algorithm is implemented in this base class and calles some few pure virtual methods.
     * The important functions you have to override are:
     * - computeRootLikelihood(size_t root, size_t l, size_t r, size_t m)
     * - computeInternalNodeLikelihood(const TopologyNode &n, size_t nIdx, size_t l, size_t r)
     * - computeTipLikelihood(const TopologyNode &node, size_t nIdx)
     * - getRootFrequencies()
     * - updateTransitionProbabilities()
     *
     *
     * The data are stored for convenience in this class in a matrix (std::vector<std::vector< unsigned > >) and can
     * be compressed.
     *
     * The partial likelihoods are stored in a c-style array called partialLikelihoods. The dimension are
     * partialLikelihoods[active][node_index][siteRateIndex][siteIndex][charIndex], however, since this is a one-dimensional c-style array,
     * you have to access the partialLikelihoods via
     * partialLikelihoods[active*num_nodes*num_site_mixtures*pattern_block_size*num_chars +
     *                    node_index*num_site_mixtures*pattern_block_size*num_chars +
     *                    siteRateIndex*pattern_block_size*num_chars +
     *                    siteIndex*num_chars +
     *                    charIndex]
     * Since this is a bit complex, we have some offset variables for convenience:
     * activeLikelihoodOffset      =  num_nodes*num_site_mixtures*pattern_block_size*num_chars;
     * nodeOffset                  =  num_site_mixtures*pattern_block_size*num_chars;
     * mixtureOffset               =  pattern_block_size*num_chars;
     * siteOffset                  =  num_chars;
     * This gives the more convenient access via
     * partialLikelihoods[active*activeLikelihoodOffset + node_index*nodeOffset + siteRateIndex*mixtureOffset + siteIndex*siteOffset + charIndex]
     *
     * Our implementation of the partial likelihoods mean that we can store the partial likelihood of a node, but not for site rates.
     * We also use twice as much memory because we store the partial likelihood along each branch and not only for each internal node.
     * This gives us a speed improvement during MCMC proposal in the order of a factor 2.
     *
     *
     *
     * @copyright Copyright 2009-
     * @author The RevBayes Development Core Team (Sebastian Hoehna)
     * @since 2012-06-17, version 1.0
     */
    template<class charType>
    class AbstractPhyloCTMCSiteHomogeneous : public TypedDistribution< AbstractHomologousDiscreteCharacterData >, public MemberObject< RbVector<double> >, public TreeChangeEventListener {

    public:
        // Note, we need the size of the alignment in the constructor to correctly simulate an initial state
        AbstractPhyloCTMCSiteHomogeneous(const TypedDagNode<Tree> *t, size_t nChars, size_t nMix, bool c, size_t nSites, bool amb, bool wd = false );
        AbstractPhyloCTMCSiteHomogeneous(const AbstractPhyloCTMCSiteHomogeneous &n);                                                                                          //!< Copy constructor
        virtual                                                            ~AbstractPhyloCTMCSiteHomogeneous(void);                                                              //!< Virtual destructor

        // public member functions
        // pure virtual
        virtual AbstractPhyloCTMCSiteHomogeneous*                           clone(void) const = 0;                                                                      //!< Create an independent clone

        // non-virtual
        void                                                                bootstrap(void);
        virtual double                                                      computeLnProbability(void);
		virtual std::vector<charType>										drawAncestralStatesForNode(const TopologyNode &n);
        virtual void                                                        drawJointConditionalAncestralStates(std::vector<std::vector<charType> >& startStates, std::vector<std::vector<charType> >& endStates);
        void                                                                executeMethod(const std::string &n, const std::vector<const DagNode*> &args, RbVector<double> &rv) const;     //!< Map the member methods to internal function calls
        void                                                                fireTreeChangeEvent(const TopologyNode &n, const unsigned& m=0);                                                 //!< The tree has changed and we want to know which part.
        virtual void                                                        recursivelyDrawJointConditionalAncestralStates(const TopologyNode &node, std::vector<std::vector<charType> >& startStates, std::vector<std::vector<charType> >& endStates, const std::vector<size_t>& sampledSiteRates);
        virtual void                                                        redrawValue(void);
        void                                                                reInitialized(void);
        void                                                                setMcmcMode(bool tf);                                                                       //!< Change the likelihood computation to or from MCMC mode.
        void                                                                setValue(AbstractHomologousDiscreteCharacterData *v, bool f=false);                                   //!< Set the current value, e.g. attach an observation (clamp)
        virtual void                                                        tipDrawJointConditionalAncestralStates(const TopologyNode &node, std::vector<std::vector<charType> >& startStates, std::vector<std::vector<charType> >& endStates, const std::vector<size_t>& sampledSiteRates);
        void																updateMarginalNodeLikelihoods(void);

        void                                                                setClockRate(const TypedDagNode< double > *r);
        void                                                                setClockRate(const TypedDagNode< RbVector< double > > *r);
        void                                                                setPInv(const TypedDagNode< double > *);
        void                                                                setRateMatrix(const TypedDagNode< RateGenerator > *rm);
        void                                                                setRateMatrix(const TypedDagNode< RbVector< RateGenerator > > *rm);
        void                                                                setRootFrequencies(const TypedDagNode< RbVector< double > > *f);
        void                                                                setSiteRates(const TypedDagNode< RbVector< double > > *r);
        void                                                                setUseMarginalLikelihoods(bool tf);
        void                                                                setUseSiteMatrices(bool sm, const TypedDagNode< RbVector< double > > *s = NULL);


    protected:

        // helper method for this and derived classes
        void                                                                recursivelyFlagNodeDirty(const TopologyNode& n);
        virtual void                                                        resizeLikelihoodVectors(void);
        virtual void                                                        setActivePIDSpecialized(size_t i, size_t n);                                                          //!< Set the number of processes for this distribution.

        virtual void                                                        updateTransitionProbabilities(size_t node_idx, double brlen);
        virtual std::vector<double>                                         getRootFrequencies( size_t mixture = 0 ) const;
        virtual void                                                        getRootFrequencies( std::vector<std::vector<double> >& ) const;
        virtual std::vector<double>                                         getMixtureProbs( void ) const;
        virtual double                                                      getPInv(void) const;


        // Parameter management functions.
        virtual void                                                        swapParameterInternal(const DagNode *oldP, const DagNode *newP);                                    //!< Swap a parameter


        // virtual methods that may be overwritten, but then the derived class should call this methods
        virtual void                                                        keepSpecialization(DagNode* affecter);
        virtual void                                                        restoreSpecialization(DagNode *restorer);
        virtual void                                                        touchSpecialization(DagNode *toucher, bool touchAll);

        // pure virtual methods
        virtual void                                                        computeInternalNodeLikelihood(const TopologyNode &n, size_t nIdx, size_t l, size_t r) = 0;
        virtual void                                                        computeInternalNodeLikelihood(const TopologyNode &n, size_t nIdx, size_t l, size_t r, size_t m) = 0;
        virtual void                                                        computeTipLikelihood(const TopologyNode &node, size_t nIdx) = 0;
        virtual void                                                        computeRootLikelihood( size_t root, size_t left, size_t right) = 0;
        virtual void                                                        computeRootLikelihood( size_t root, size_t left, size_t right, size_t middle) = 0;

        // virtual methods that you may want to overwrite
        virtual void                                                        compress(void);
        virtual void                                                        computeMarginalNodeLikelihood(size_t node_idx, size_t parentIdx);
        virtual void                                                        computeMarginalRootLikelihood();
        virtual std::vector< std::vector< double > >*                       sumMarginalLikelihoods(size_t node_index);
        virtual void                                                        computeRootLikelihoods( std::vector< double > &rv ) const;
        virtual double                                                      sumRootLikelihood( void );
        virtual std::vector<size_t>                                         getIncludedSiteIndices();


        // members
        double                                                              lnProb;
        double                                                              storedLnProb;
        size_t                                                              num_nodes;
        size_t                                                              num_sites;
        const size_t                                                        num_chars;
        size_t                                                              num_site_rates;
        size_t                                                              num_site_mixtures;
        size_t                                                              num_matrices;
        const TypedDagNode<Tree>*                                           tau;
        std::vector<TransitionProbabilityMatrix>                            transition_prob_matrices;

        // the likelihoods
        double*                                                             partialLikelihoods;
        std::vector<size_t>                                                 activeLikelihood;
		double*																marginalLikelihoods;

        std::vector< std::vector< std::vector<double> > >                   perNodeSiteLogScalingFactors;

        // the data
        std::vector<std::vector<RbBitSet> >                                 ambiguous_char_matrix;
        std::vector<std::vector<unsigned long> >                            char_matrix;
        std::vector<std::vector<bool> >                                     gap_matrix;
        std::vector<size_t>                                                 pattern_counts;
        std::vector<bool>                                                   site_invariant;
        std::vector<size_t>                                                 invariant_site_index;
        size_t                                                              num_patterns;
        bool                                                                compressed;
		std::vector<size_t>                                                 site_pattern;    // an array that keeps track of which pattern is used for each site

        // flags for likelihood recomputation
        bool                                                                touched;
        std::vector<bool>                                                   changed_nodes;
        std::vector<bool>                                                   dirty_nodes;

        // offsets for nodes
        size_t                                                              activeLikelihoodOffset;
        size_t                                                              nodeOffset;
        size_t                                                              mixtureOffset;
        size_t                                                              siteOffset;
        size_t                                                              nodeOffsetMarginal;
        size_t                                                              siteOffsetMarginal;

        // flags
        bool                                                                using_ambiguous_characters;
        bool                                                                treatUnknownAsGap;
        bool                                                                treatAmbiguousAsGaps;

        bool                                                                using_weighted_characters;

        bool                                                                useMarginalLikelihoods;
        bool                                                                inMcmcMode;

        // members
        const TypedDagNode< double >*                                       homogeneous_clock_rate;
        const TypedDagNode< RbVector< double > >*                           heterogeneous_clock_rates;
        const TypedDagNode< RateGenerator >*                                homogeneous_rate_matrix;
        const TypedDagNode< RbVector< RateGenerator > >*                    heterogeneous_rate_matrices;
        const TypedDagNode< RbVector< double > >*                           root_frequencies;
        const TypedDagNode< RbVector< double > >*                           site_rates;
        const TypedDagNode< RbVector< double > >*                           site_matrix_probs;
        const TypedDagNode< RbVector< double > >*                           site_rates_probs;
        const TypedDagNode< double >*                                       p_inv;


        // flags specifying which model variants we use
        bool                                                                branch_heterogeneous_clock_rates;
        bool                                                                branch_heterogeneous_substitution_matrices;
        bool                                                                rate_variation_across_sites;

        // MPI variables
        size_t                                                              pattern_block_start;
        size_t                                                              pattern_block_end;
        size_t                                                              pattern_block_size;

        charType                                                            template_state;                                 //!< Template state used for ancestral state estimation. This makes sure that the state labels are preserved.

    private:

        // private methods
        void                                                                fillLikelihoodVector(const TopologyNode &n, size_t nIdx);
        void                                                                recursiveMarginalLikelihoodComputation(size_t nIdx);
        virtual void                                                        scale(size_t i);
        virtual void                                                        scale(size_t i, size_t l, size_t r);
        virtual void                                                        scale(size_t i, size_t l, size_t r, size_t m);
        void                                                                simulate(const TopologyNode& node, std::vector< DiscreteTaxonData< charType > > &t, const std::vector<bool> &inv, const std::vector<size_t> &perSiteRates);



    };

}


#include "DiscreteCharacterState.h"
#include "HomologousDiscreteCharacterData.h"
#include "RandomNumberFactory.h"
#include "RandomNumberGenerator.h"
#include "RateMatrix_JC.h"
#include "StochasticNode.h"
#include "TopologyNode.h"
#include "TransitionProbabilityMatrix.h"

#include <cmath>

#ifdef RB_MPI
#include <mpi.h>
#endif


template<class charType>
RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::AbstractPhyloCTMCSiteHomogeneous(const TypedDagNode<Tree> *t, size_t nChars, size_t nMix, bool c, size_t nSites,  bool amb, bool wd) :
    TypedDistribution< AbstractHomologousDiscreteCharacterData >(  NULL ),
    lnProb( 0.0 ),
    storedLnProb( 0.0 ),
    num_nodes( t->getValue().getNumberOfNodes() ),
    num_sites( nSites ),
    num_chars( nChars ),
    num_site_rates( nMix ),
    num_site_mixtures( nMix ),
    num_matrices( 1 ),
    tau( t ),
    transition_prob_matrices( std::vector<TransitionProbabilityMatrix>(num_site_mixtures, TransitionProbabilityMatrix(num_chars) ) ),
//    partialLikelihoods( new double[2*num_nodes*num_site_mixtures*num_sites*num_chars] ),
    partialLikelihoods( NULL ),
    activeLikelihood( std::vector<size_t>(num_nodes, 0) ),
//    marginalLikelihoods( new double[num_nodes*num_site_mixtures*num_sites*num_chars] ),
    marginalLikelihoods( NULL ),
    perNodeSiteLogScalingFactors( std::vector<std::vector< std::vector<double> > >(2, std::vector<std::vector<double> >(num_nodes, std::vector<double>(num_sites, 0.0) ) ) ),
    ambiguous_char_matrix(),
    char_matrix(),
    gap_matrix(),
    pattern_counts(),
    site_invariant( num_sites, false ),
    invariant_site_index( num_sites, 0 ),
    num_patterns( num_sites ),
    compressed( c ),
    site_pattern( std::vector<size_t>(num_sites, 0) ),
    touched( false ),
    changed_nodes( std::vector<bool>(num_nodes, false) ),
    dirty_nodes( std::vector<bool>(num_nodes, true) ),
    using_ambiguous_characters( amb ),
    treatUnknownAsGap( true ),
    treatAmbiguousAsGaps( false ),
    using_weighted_characters( wd ),
    useMarginalLikelihoods( false ),
    inMcmcMode( false ),
    pattern_block_start( 0 ),
    pattern_block_end( num_patterns ),
    pattern_block_size( num_patterns ),
    template_state()
{

    // initialize with default parameters
    homogeneous_clock_rate        = NULL;
    heterogeneous_clock_rates     = NULL;
    homogeneous_rate_matrix       = NULL;
    heterogeneous_rate_matrices   = NULL;
    root_frequencies              = NULL;
    site_rates                    = NULL;
    site_matrix_probs             = NULL;
    site_rates_probs              = NULL;
    p_inv                         = NULL;

    // flags specifying which model variants we use
    branch_heterogeneous_clock_rates               = false;
    branch_heterogeneous_substitution_matrices     = true;
    rate_variation_across_sites                    = false;


    tau->getValue().getTreeChangeEventHandler().addListener( this );

    activeLikelihoodOffset      =  num_nodes*num_site_mixtures*pattern_block_size*num_chars;
    nodeOffset                  =  num_site_mixtures*pattern_block_size*num_chars;
    mixtureOffset               =  pattern_block_size*num_chars;
    siteOffset                  =  num_chars;


    // add the parameters to our set (in the base class)
    // in that way other class can easily access the set of our parameters
    // this will also ensure that the parameters are not getting deleted before we do
    this->addParameter( tau );
    this->addParameter( homogeneous_clock_rate );
    this->addParameter( heterogeneous_clock_rates );
    this->addParameter( homogeneous_rate_matrix );
    this->addParameter( heterogeneous_rate_matrices );
    this->addParameter( root_frequencies );
    this->addParameter( site_rates );
    this->addParameter( site_matrix_probs );
    this->addParameter( site_rates_probs );
    this->addParameter( p_inv );

    // initially we use only a single processor until someone else tells us otherwise
    this->setActivePID( this->pid, 1 );

}


template<class charType>
RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::AbstractPhyloCTMCSiteHomogeneous(const AbstractPhyloCTMCSiteHomogeneous &n) :
    TypedDistribution< AbstractHomologousDiscreteCharacterData >( n ),
    lnProb( n.lnProb ),
    storedLnProb( n.storedLnProb ),
    num_nodes( n.num_nodes ),
    num_sites( n.num_sites ),
    num_chars( n.num_chars ),
    num_site_rates( n.num_site_rates ),
    num_site_mixtures( n.num_site_mixtures ),
    num_matrices( n.num_matrices ),
    tau( n.tau ),
    transition_prob_matrices( n.transition_prob_matrices ),
//    partialLikelihoods( new double[2*num_nodes*num_site_mixtures*num_sites*num_chars] ),
    partialLikelihoods( NULL ),
    activeLikelihood( n.activeLikelihood ),
//    marginalLikelihoods( new double[num_nodes*num_site_mixtures*num_sites*num_chars] ),
    marginalLikelihoods( NULL ),
    perNodeSiteLogScalingFactors( n.perNodeSiteLogScalingFactors ),
    ambiguous_char_matrix( n.ambiguous_char_matrix ),
    char_matrix( n.char_matrix ),
    gap_matrix( n.gap_matrix ),
    pattern_counts( n.pattern_counts ),
    site_invariant( n.site_invariant ),
    invariant_site_index( n.invariant_site_index ),
    num_patterns( n.num_patterns ),
    compressed( n.compressed ),
    site_pattern( n.site_pattern ),
    touched( false ),
    changed_nodes( n.changed_nodes ),
    dirty_nodes( n.dirty_nodes ),
    using_ambiguous_characters( n.using_ambiguous_characters ),
    treatUnknownAsGap( n.treatUnknownAsGap ),
    treatAmbiguousAsGaps( n.treatAmbiguousAsGaps ),
    using_weighted_characters( n.using_weighted_characters ),
    useMarginalLikelihoods( n.useMarginalLikelihoods ),
    inMcmcMode( n.inMcmcMode ),
    pattern_block_start( n.pattern_block_start ),
    pattern_block_end( n.pattern_block_end ),
    pattern_block_size( n.pattern_block_size ),
    template_state( n.template_state )
{

    // initialize with default parameters
    homogeneous_clock_rate       = n.homogeneous_clock_rate;
    heterogeneous_clock_rates    = n.heterogeneous_clock_rates;
    homogeneous_rate_matrix      = n.homogeneous_rate_matrix;
    heterogeneous_rate_matrices  = n.heterogeneous_rate_matrices;
    root_frequencies             = n.root_frequencies;
    site_rates                   = n.site_rates;
    site_matrix_probs            = n.site_matrix_probs;
    site_rates_probs             = n.site_rates_probs;
    p_inv                        = n.p_inv;

    activeLikelihoodOffset      =  n.activeLikelihoodOffset;
    nodeOffset                  =  n.nodeOffset;
    mixtureOffset               =  n.mixtureOffset;
    siteOffset                  =  n.siteOffset;

    // flags specifying which model variants we use
    branch_heterogeneous_clock_rates               = n.branch_heterogeneous_clock_rates;
    branch_heterogeneous_substitution_matrices     = n.branch_heterogeneous_substitution_matrices;
    rate_variation_across_sites                    = n.rate_variation_across_sites;

    tau->getValue().getTreeChangeEventHandler().addListener( this );

    // copy the partial likelihoods if necessary
    if ( inMcmcMode == true )
    {
        partialLikelihoods = new double[2*activeLikelihoodOffset];
        memcpy(partialLikelihoods, n.partialLikelihoods, 2*activeLikelihoodOffset*sizeof(double));
    }

    // copy the marginal likelihoods if necessary
    if ( useMarginalLikelihoods == true )
    {
        marginalLikelihoods = new double[activeLikelihoodOffset];
        memcpy(marginalLikelihoods, n.marginalLikelihoods, activeLikelihoodOffset*sizeof(double));
    }
}


/**
 * Destructor. Because we added ourselves as a reference to tau when we added a listener to its
 * TreeChangeEventHandler, we need to remove ourselves as a reference and possibly delete tau
 * when we die. All other parameters are handled by others.
 */
template<class charType>
RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::~AbstractPhyloCTMCSiteHomogeneous( void )
{
    // We don't delete the params, because they might be used somewhere else too. The model needs to do that!

    // remove myself from the tree listeners
    if ( tau != NULL )
    {
        tau->getValue().getTreeChangeEventHandler().removeListener( this );
    }

    // free the partial likelihoods
    delete [] partialLikelihoods;
    delete [] marginalLikelihoods;
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::bootstrap( void )
{

    // first we re-compress the data
    compress();

    RandomNumberGenerator *rng = GLOBAL_RNG;

    std::vector<size_t> bootstrapped_pattern_counts = std::vector<size_t>(num_patterns,0);

    for (size_t i = 0; i<num_sites; ++i)
    {
        double u = rng->uniform01() * num_sites;
        size_t pattern_index = 0;
        while ( u > double(pattern_counts[pattern_index]) )
        {
            u -= double(pattern_counts[pattern_index]);
            ++pattern_index;
        }

        ++bootstrapped_pattern_counts[pattern_index];

    }

    pattern_counts = bootstrapped_pattern_counts;

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::compress( void )
{

    // only if the value has been set
    if ( this->value == NULL )
    {
        return;
    }

    ambiguous_char_matrix.clear();
    char_matrix.clear();
    gap_matrix.clear();
    pattern_counts.clear();
    num_patterns = 0;

    // resize the matrices
    size_t tips = tau->getValue().getNumberOfTips();
    ambiguous_char_matrix.resize(tips);
    char_matrix.resize(tips);
    gap_matrix.resize(tips);

    // create a vector with the correct site indices
    // some of the sites may have been excluded
    std::vector<size_t> siteIndices = getIncludedSiteIndices();

    // check whether there are ambiguous characters (besides gaps)
    bool ambiguousCharacters = false;

    // find the unique site patterns and compute their respective frequencies
    std::vector<TopologyNode*> nodes = tau->getValue().getNodes();
    for (size_t site = 0; site < num_sites; ++site)
    {

        for (std::vector<TopologyNode*>::iterator it = nodes.begin(); it != nodes.end(); ++it)
        {
            if ( (*it)->isTip() )
            {
                AbstractDiscreteTaxonData& taxon = value->getTaxonData( (*it)->getName() );
                DiscreteCharacterState &c = taxon.getCharacter(siteIndices[site]);

                // if we treat unknown characters as gaps and this is an unknown character then we change it
                // because we might then have a pattern more
                if ( treatAmbiguousAsGaps && (c.isAmbiguous() || c.isMissingState()) )
                {
                    c.setGapState( true );
                }
                else if ( treatUnknownAsGap && (c.getNumberOfStates() == c.getNumberObservedStates() || c.isMissingState()) )
                {
                    c.setGapState( true );
                }
                else if ( !c.isGapState() && (c.isAmbiguous() || c.isMissingState()) )
                {
                    ambiguousCharacters = true;
                    break;
                }
            }
        }

        // break the loop if there was an ambiguous character
        if ( ambiguousCharacters )
        {
            break;
        }
    }

    // set the global variable if we use ambiguous characters
    using_ambiguous_characters = ambiguousCharacters;

    // check whether there are weighted characters
    bool weightedCharacters = false;

    for (size_t site = 0; site < num_sites; ++site)
    {

        for (std::vector<TopologyNode*>::iterator it = nodes.begin(); it != nodes.end(); ++it)
        {
            if ( (*it)->isTip() )
            {
                AbstractDiscreteTaxonData& taxon = value->getTaxonData( (*it)->getName() );
                DiscreteCharacterState &c = taxon.getCharacter(siteIndices[site]);

                if (c.isWeighted() )
                {
                  weightedCharacters = true;
                  break;
                }
            }
        }

        // break the loop if there was an ambiguous character
        if ( weightedCharacters )
        {
            break;
        }
    }

    // set the global variable if we use ambiguous characters
    using_weighted_characters = weightedCharacters;

    std::vector<bool> unique(num_sites, true);
    std::vector<size_t> indexOfSitePattern;

    // compress the character matrix if we're asked to
    if ( compressed == true )
    {
        // find the unique site patterns and compute their respective frequencies
        std::map<std::string,size_t> patterns;
        for (size_t site = 0; site < num_sites; ++site)
        {
            // create the site pattern
            std::string pattern = "";
            for (std::vector<TopologyNode*>::iterator it = nodes.begin(); it != nodes.end(); ++it)
            {
                if ( (*it)->isTip() )
                {
                    AbstractDiscreteTaxonData& taxon = value->getTaxonData( (*it)->getName() );
                    CharacterState &c = taxon.getCharacter(siteIndices[site]);
                    pattern += c.getStringValue();
                }
            }
            // check if we have already seen this site pattern
            std::map<std::string, size_t>::const_iterator index = patterns.find( pattern );
            if ( index != patterns.end() )
            {
                // we have already seen this pattern
                // increase the frequency counter
                pattern_counts[ index->second ]++;

                // obviously this site isn't unique nor the first encounter
                unique[site] = false;

				// remember which pattern this site uses
				site_pattern[site] = index->second;
            }
            else
            {
                // create a new pattern frequency counter for this pattern
                pattern_counts.push_back(1);

                // insert this pattern with the corresponding index in the map
                patterns.insert( std::pair<std::string,size_t>(pattern,num_patterns) );

				// remember which pattern this site uses
				site_pattern[site] = num_patterns;

                // increase the pattern counter
                num_patterns++;

                // add the index of the site to our pattern-index vector
                indexOfSitePattern.push_back( site );

                // flag that this site is unique (or the first occurence of this pattern)
                unique[site] = true;
            }
        }
    }
    else
    {
        // we do not compress
        num_patterns = num_sites;
        pattern_counts = std::vector<size_t>(num_sites,1);
        for(size_t i = 0; i < this->num_sites; i++)
		{
			indexOfSitePattern[i] = i;
		}
    }


    // compute which block of the data this process needs to compute
    pattern_block_start = size_t(floor( (double(pid-active_PID)   / num_processes ) * num_patterns) );
    pattern_block_end   = size_t(floor( (double(pid+1-active_PID) / num_processes ) * num_patterns) );
    pattern_block_size  = pattern_block_end - pattern_block_start;


    std::vector<size_t> process_pattern_counts = std::vector<size_t>(pattern_block_size,0);
    // allocate and fill the cells of the matrices
    for (std::vector<TopologyNode*>::iterator it = nodes.begin(); it != nodes.end(); ++it)
    {
        if ( (*it)->isTip() )
        {
            size_t node_index = (*it)->getIndex();
            AbstractDiscreteTaxonData& taxon = value->getTaxonData( (*it)->getName() );

            // resize the column
            ambiguous_char_matrix[node_index].resize(pattern_block_size);
            char_matrix[node_index].resize(pattern_block_size);
            gap_matrix[node_index].resize(pattern_block_size);
            for (size_t patternIndex = 0; patternIndex < pattern_block_size; ++patternIndex)
            {
                // set the counts for this patter
                process_pattern_counts[patternIndex] = pattern_counts[patternIndex+pattern_block_start];

                charType &c = static_cast<charType &>( taxon.getCharacter(siteIndices[indexOfSitePattern[patternIndex+pattern_block_start]]) );
                gap_matrix[node_index][patternIndex] = c.isGapState();

                if ( using_ambiguous_characters == true )
                {
                    // we use the actual state
                    ambiguous_char_matrix[node_index][patternIndex] = c.getState();
                }
                else if ( c.isGapState() == false )
                {
                    // we use the index of the state
                    char_matrix[node_index][patternIndex] = c.getStateIndex();
                }
                else
                {
                    // just to be safe
                    char_matrix[node_index][patternIndex] = -1;
                }

            }

        }

    }

    // now copy back the pattern count vector
    pattern_counts = process_pattern_counts;

    // reset the vector if a site is invariant
    site_invariant.resize( pattern_block_size );
    invariant_site_index.resize( pattern_block_size );
    size_t length = char_matrix.size();
    for (size_t i=0; i<pattern_block_size; ++i)
    {
        bool inv = true;

        if ( using_ambiguous_characters == true )
        {
            const RbBitSet &val = ambiguous_char_matrix[0][i];

            invariant_site_index[i] = val.size();

            for (size_t j=1; j<length; ++j)
            {
                if ( val != ambiguous_char_matrix[j][i] || gap_matrix[j][i] == true )
                {
                    inv = false;
                    break;
                }
            }
        }
        else
        {
            unsigned long c = char_matrix[0][i];
            invariant_site_index[i] = c;

            for (size_t j=1; j<length; ++j)
            {
                if ( invariant_site_index[i] != char_matrix[j][i] || gap_matrix[j][i] == true )
                {
                    inv = false;
                    break;
                }
            }
        }

        site_invariant[i] = inv;
    }

    // finally we resize the partial likelihood vectors to the new pattern counts
    resizeLikelihoodVectors();

}


template<class charType>
double RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::computeLnProbability( void )
{

    // we need to check here if we still are listining to this tree for change events
    // the tree could have been replaced without telling us
    if ( tau->getValue().getTreeChangeEventHandler().isListening( this ) == false )
    {
        tau->getValue().getTreeChangeEventHandler().addListener( this );
        dirty_nodes = std::vector<bool>(num_nodes, true);
    }


    // if we are not in MCMC mode, then we need to (temporarily) allocate memory
    if ( inMcmcMode == false )
    {
        partialLikelihoods = new double[2*activeLikelihoodOffset];
    }

    // compute the ln probability by recursively calling the probability calculation for each node
    const TopologyNode &root = tau->getValue().getRoot();

    // we start with the root and then traverse down the tree
    size_t root_index = root.getIndex();

    // only necessary if the root is actually dirty
    if ( dirty_nodes[root_index] == true )
    {

        // start by filling the likelihood vector for the children of the root
        if ( root.getNumberOfChildren() == 2 ) // rooted trees have two children for the root
        {
            const TopologyNode &left = root.getChild(0);
            size_t left_index = left.getIndex();
            fillLikelihoodVector( left, left_index );
            const TopologyNode &right = root.getChild(1);
            size_t right_index = right.getIndex();
            fillLikelihoodVector( right, right_index );

            computeRootLikelihood( root_index, left_index, right_index );
            scale(root_index, left_index, right_index);

        }
        else if ( root.getNumberOfChildren() == 3 ) // unrooted trees have three children for the root
        {
            const TopologyNode &left = root.getChild(0);
            size_t left_index = left.getIndex();
            fillLikelihoodVector( left, left_index );
            const TopologyNode &right = root.getChild(1);
            size_t right_index = right.getIndex();
            fillLikelihoodVector( right, right_index );
            const TopologyNode &middle = root.getChild(2);
            size_t middleIndex = middle.getIndex();
            fillLikelihoodVector( middle, middleIndex );

            computeRootLikelihood( root_index, left_index, right_index, middleIndex );
            scale(root_index, left_index, right_index, middleIndex);

        }
        else
        {
            throw RbException("The root node has an unexpected number of children. Only 2 (for rooted trees) or 3 (for unrooted trees) are allowed.");
        }

        // sum the partials up
        this->lnProb = sumRootLikelihood();

    }

    // if we are not in MCMC mode, then we need to (temporarily) free memory
    if ( inMcmcMode == false )
    {
        // free the partial likelihoods
        delete [] partialLikelihoods;
        partialLikelihoods = NULL;
    }

    return this->lnProb;
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::computeMarginalNodeLikelihood( size_t node_index, size_t parentnode_index )
{

    // compute the transition probability matrix
    this->updateTransitionProbabilities( node_index, this->tau->getValue().getNode(node_index).getBranchLength() );

    // get the pointers to the partial likelihoods and the marginal likelihoods
    const double*   p_node                  = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;
    double*         p_node_marginal         = this->marginalLikelihoods + node_index*this->nodeOffset;
    const double*   p_parent_node_marginal  = this->marginalLikelihoods + parentnode_index*this->nodeOffset;

    // get pointers the likelihood for both subtrees
    const double*   p_mixture                   = p_node;
    double*         p_mixture_marginal          = p_node_marginal;
    const double*   p_parent_mixture_marginal   = p_parent_node_marginal;

    // iterate over all mixture categories
    for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
    {
        // the transition probability matrix for this mixture category
        const double*    tp_begin                = this->transition_prob_matrices[mixture].theMatrix;

        // get pointers to the likelihood for this mixture category
        const double*   p_site_mixture                  = p_mixture;
        double*         p_site_mixture_marginal         = p_mixture_marginal;
        const double*   p_parent_site_mixture_marginal  = p_parent_mixture_marginal;
        // iterate over all sites
        for (size_t site = 0; site < this->pattern_block_size; ++site)
        {
            // get the pointers to the likelihoods for this site and mixture category
            const double*   p_site_j                    = p_site_mixture;
            double*         p_site_marginal_j           = p_site_mixture_marginal;
            // iterate over all end states
            for (size_t j=0; j<num_chars; ++j)
            {
                const double*   p_parent_site_marginal_k    = p_parent_site_mixture_marginal;
                *p_site_marginal_j = 0.0;

                // iterator over all start states
                for (size_t k=0; k<num_chars; ++k)
                {
                    // transition probability for k->j
                    const double tp_kj = *p_parent_site_marginal_k * tp_begin[ k * num_chars + j ];

                    // add the probability of starting from this state
                    *p_site_marginal_j += *p_site_j * tp_kj;

                    // next parent state
                    ++p_parent_site_marginal_k;
                }

                // increment pointers
                ++p_site_j; ++p_site_marginal_j;
            }

            // increment the pointers to the next site
            p_site_mixture+=this->siteOffset; p_site_mixture_marginal+=this->siteOffset; p_parent_site_mixture_marginal+=this->siteOffset;

        } // end-for over all sites (=patterns)

        // increment the pointers to the next mixture category
        p_mixture+=this->mixtureOffset; p_mixture_marginal+=this->mixtureOffset; p_parent_mixture_marginal+=this->mixtureOffset;

    } // end-for over all mixtures (=rate categories)

}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::computeMarginalRootLikelihood( void )
{
    // get the root node
    const TopologyNode &root = tau->getValue().getRoot();

    // get root frequencies
    std::vector<std::vector<double> >   ff;
    getRootFrequencies(ff);

    // get the index of the root node
    size_t node_index = root.getIndex();

    // get the pointers to the partial likelihoods and the marginal likelihoods
    const double*   p_node           = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;
    double*         p_node_marginal  = this->marginalLikelihoods + node_index*this->nodeOffset;

    // get pointers the likelihood for both subtrees
    const double*   p_mixture           = p_node;
    double*         p_mixture_marginal  = p_node_marginal;

    // iterate over all mixture categories
    for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
    {
        // get root frequencies
        const std::vector<double>&          f           = ff[mixture % ff.size()];
        std::vector<double>::const_iterator f_end       = f.end();
        std::vector<double>::const_iterator f_begin     = f.begin();

        // get pointers to the likelihood for this mixture category
        const double*   p_site_mixture          = p_mixture;
        double*         p_site_mixture_marginal = p_mixture_marginal;
        // iterate over all sites
        for (size_t site = 0; site < this->pattern_block_size; ++site)
        {
            // get the pointer to the stationary frequencies
            std::vector<double>::const_iterator f_j             = f_begin;
            // get the pointers to the likelihoods for this site and mixture category
            const double*   p_site_j            = p_site_mixture;
            double*         p_site_marginal_j   = p_site_mixture_marginal;
            // iterate over all starting states
            for (; f_j != f_end; ++f_j)
            {
                // add the probability of starting from this state
                *p_site_marginal_j = *p_site_j * *f_j;

                // increment pointers
                ++p_site_j; ++p_site_marginal_j;
            }

            // increment the pointers to the next site
            p_site_mixture+=this->siteOffset; p_site_mixture_marginal+=this->siteOffset;

        } // end-for over all sites (=patterns)

        // increment the pointers to the next mixture category
        p_mixture+=this->mixtureOffset; p_mixture_marginal+=this->mixtureOffset;

    } // end-for over all mixtures (=rate categories)

}


/**
 * Draw a vector of ancestral states from the marginal distribution (non-conditional of the other ancestral states).
 * Here we assume that the marginal likelihoods have been updated.
 */
template<class charType>
std::vector<charType> RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::drawAncestralStatesForNode(const TopologyNode &node)
{

	size_t node_index = node.getIndex();

	// get the marginal likelihoods
    std::vector< std::vector<double> >* marginals = sumMarginalLikelihoods(node_index);

	RandomNumberGenerator* rng = GLOBAL_RNG;
	std::vector< charType > ancestralSeq = std::vector<charType>();

    for ( size_t i = 0; i < num_sites; ++i )
    {
		size_t pattern = i;
		// if the matrix is compressed use the pattern for this site
		if (compressed)
        {
			pattern = site_pattern[i];
		}

        // create the character
        charType c = charType( num_chars );
        c.setToFirstState();

		// sum the likelihoods for each character state
		const std::vector<double> siteMarginals = (*marginals)[pattern];
		double sumMarginals = 0.0;
		for (int j = 0; j < siteMarginals.size(); j++)
        {
			sumMarginals += siteMarginals[j];
		}

		double u = rng->uniform01();
		if (sumMarginals == 0.0)
        {

			// randomly draw state if all states have 0 probability
			c.setStateByIndex((size_t)(u*c.getNumberOfStates()));

		}
        else
        {

			// the marginals don't add up to 1, so rescale u
			u *= sumMarginals;

			// draw the character state
			size_t stateIndex = 0;
			while ( true )
            {

				u -= siteMarginals[stateIndex];

				if ( u > 0.0 )
                {

					c++;
					stateIndex++;

					if ( stateIndex == c.getNumberOfStates() )
                    {
						stateIndex = 0;
						c.setToFirstState();
					}

				}
                else
                {
					break;
				}
			}
		}

        // add the character to the sequence
        ancestralSeq.push_back( c );
    }

    // we need to free the vector
    delete marginals;

	return ancestralSeq;
}


/**
 * Draw a vector of ancestral states from the joint-conditional distribution of states.
 */
template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::drawJointConditionalAncestralStates(std::vector<std::vector<charType> >& startStates, std::vector<std::vector<charType> >& endStates)
{

    RandomNumberGenerator* rng = GLOBAL_RNG;

    // get working variables
    std::vector<double> siteProbVector = getMixtureProbs();

    const TopologyNode &root = tau->getValue().getRoot();
    size_t node_index = root.getIndex();
    size_t right = root.getChild(0).getIndex();
    size_t left = root.getChild(1).getIndex();

    // get the pointers to the partial likelihoods and the marginal likelihoods
    double*         p_node  = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;
    const double*   p_left  = this->partialLikelihoods + this->activeLikelihood[left]*this->activeLikelihoodOffset + left*this->nodeOffset;
    const double*   p_right = this->partialLikelihoods + this->activeLikelihood[right]*this->activeLikelihoodOffset + right*this->nodeOffset;

    // get pointers the likelihood for both subtrees
    const double*   p_site           = p_node;
    const double*   p_left_site      = p_left;
    const double*   p_right_site     = p_right;

    // get root frequencies
    std::vector<std::vector<double> >   ff;
    getRootFrequencies(ff);

    // sample root states
    std::vector<double> p( this->num_site_mixtures*this->num_chars, 0.0);
    std::vector<size_t> sampledSiteRates(this->num_sites,0);

    for (size_t i = 0; i < this->num_sites; i++)
    {

        // create the character
        charType c = charType( template_state );

        // sum to sample
        double sum = 0.0;

		// if the matrix is compressed use the pattern for this site
        size_t pattern = i;
		if ( compressed == true )
        {
			pattern = site_pattern[i];
		}

        // get ptr to first mixture cat for site
        p_site          = p_node  + pattern * this->siteOffset;
        p_left_site     = p_left  + pattern * this->siteOffset;
        p_right_site    = p_right + pattern * this->siteOffset;

        // iterate over all mixture categories
        for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
        {
            // get root frequencies
            const std::vector<double>&          f           = ff[mixture % ff.size()];

            // get pointers to the likelihood for this mixture category
            const double* p_site_mixture_j       = p_site;
            const double* p_left_site_mixture_j  = p_left_site;
            const double* p_right_site_mixture_j = p_right_site;

            // iterate over all starting states
            for (size_t state = 0; state < this->num_chars; ++state)
            {
                size_t k = this->num_chars*mixture + state;
                p[k] = *p_site_mixture_j * *p_left_site_mixture_j * *p_right_site_mixture_j * f[state] * siteProbVector[mixture];
                sum += p[k];

                // increment the pointers to the next state for (site,rate)
                p_site_mixture_j++;
                p_left_site_mixture_j++;
                p_right_site_mixture_j++;
            }

            // increment the pointers to the next mixture category for given site
            p_site       += this->mixtureOffset;
            p_left_site  += this->mixtureOffset;
            p_right_site += this->mixtureOffset;

        } // end-for over all mixtures (=rate categories)

        // sample char from p
        bool stop = false;
        double u = rng->uniform01() * sum;
        for (size_t mixture = 0; mixture < this->num_site_mixtures; mixture++)
        {
            c.setToFirstState();
            for (size_t state = 0; state < this->num_chars; state++)
            {
                size_t k = this->num_chars * mixture + state;
                u -= p[k];
                if (u < 0.0)
                {
                    startStates[root.getIndex()][i] = c;
                    sampledSiteRates[i] = mixture;
                    stop = true;
                    break;
                }
                c++;
            }
            if (stop) break;
        }

        endStates[node_index][i] = startStates[node_index][i];
    }

    // recurse
    std::vector<TopologyNode*> children = root.getChildren();
    for (size_t i = 0; i < children.size(); i++)
    {
        // daughters identically inherit ancestral state
        startStates[ children[i]->getIndex() ] = endStates[ root.getIndex() ];

        // recurse towards tips
        if ( children[i]->isTip() == false )
        {
            recursivelyDrawJointConditionalAncestralStates(*children[i], startStates, endStates, sampledSiteRates);
        }
        else
        {
            tipDrawJointConditionalAncestralStates(*children[i], startStates, endStates, sampledSiteRates);
        }

    }
}

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::executeMethod(const std::string &n, const std::vector<const DagNode *> &args, RbVector<double> &rv) const
{

    if ( n == "siteLikelihoods" )
    {

        // make sure the likelihoods are updated
        const_cast<AbstractPhyloCTMCSiteHomogeneous<charType> *>( this )->computeLnProbability();

        // get the per site likelihood
        std::vector<double> tmp = std::vector<double>(num_patterns, 0.0);
        computeRootLikelihoods( tmp );

        // now match it back to the actual sites
        rv = RbVector<double>(num_sites, 0.0);
        for (size_t i=0; i<num_sites; ++i)
        {
            size_t pattern_index = site_pattern[i];
            rv[i] = tmp[pattern_index] / pattern_counts[pattern_index];
        }

    }
    else
    {
        throw RbException("The PhyloCTMC process does not have a member method called '" + n + "'.");
    }

}




template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::recursivelyDrawJointConditionalAncestralStates(const TopologyNode &node, std::vector<std::vector<charType> >& startStates, std::vector<std::vector<charType> >& endStates, const std::vector<size_t>& sampledSiteRates)
{
    RandomNumberGenerator* rng = GLOBAL_RNG;

    // get working variables
    size_t node_index = node.getIndex();
    size_t left = node.getChild(0).getIndex();
    size_t right = node.getChild(1).getIndex();
//    size_t parentIndex = node.getParent().getIndex();

    // get transition probabilities
    this->updateTransitionProbabilities( node_index, node.getBranchLength() );

    // get the pointers to the partial likelihoods and the marginal likelihoods
//    double*         p_node  = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;
    const double*   p_left  = this->partialLikelihoods + this->activeLikelihood[left]*this->activeLikelihoodOffset + left*this->nodeOffset;
    const double*   p_right = this->partialLikelihoods + this->activeLikelihood[right]*this->activeLikelihoodOffset + right*this->nodeOffset;

    // get pointers the likelihood for both subtrees
//    const double*   p_site           = p_node;
//    const double*   p_left_site      = p_left;
//    const double*   p_right_site     = p_right;

    // sample characters conditioned on start states, going to end states
    std::vector<double> p(this->num_chars, 0.0);
    for (size_t i = 0; i < this->num_sites; i++)
    {
        size_t cat = sampledSiteRates[i];
        size_t k = startStates[node_index][i].getStateIndex();


        // sum to sample
        double sum = 0.0;

		// if the matrix is compressed use the pattern for this site
        size_t pattern = i;
		if ( compressed == true )
        {
			pattern = site_pattern[i];
		}

        // get ptr to first mixture cat for site
//        p_site          = p_node  + cat * this->mixtureOffset + pattern * this->siteOffset;
        const double* p_left_site_mixture_j     = p_left  + cat * this->mixtureOffset + pattern * this->siteOffset;
        const double* p_right_site_mixture_j    = p_right + cat * this->mixtureOffset + pattern * this->siteOffset;

        // iterate over possible end states for each site given start state
        for (size_t j = 0; j < this->num_chars; j++)
        {
            double tp_kj = this->transition_prob_matrices[cat][k][j];
            p[j] = tp_kj * *p_left_site_mixture_j * *p_right_site_mixture_j;
            sum += p[j];

//            p_site_mixture_j++;
            p_left_site_mixture_j++;
            p_right_site_mixture_j++;
        }

        // sample char from p
        charType c = charType( template_state );
        double u = rng->uniform01() * sum;
        for (size_t state = 0; state < this->num_chars; state++)
        {
            u -= p[state];
            if (u < 0.0)
            {
                endStates[node_index][i] = c;
                break;
            }
            c++;
        }
    }

    // recurse
    std::vector<TopologyNode*> children = node.getChildren();
    for (size_t i = 0; i < children.size(); i++)
    {
        // daughters identically inherit ancestral state
        startStates[ children[i]->getIndex() ] = endStates[ node.getIndex() ];

        // recurse towards tips
        if ( children[i]->isTip() == false )
        {
            recursivelyDrawJointConditionalAncestralStates(*children[i], startStates, endStates, sampledSiteRates);
        }
        else
        {
            tipDrawJointConditionalAncestralStates(*children[i], startStates, endStates, sampledSiteRates);
        }

    }

}

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::tipDrawJointConditionalAncestralStates(const TopologyNode &node, std::vector<std::vector<charType> >& startStates, std::vector<std::vector<charType> >& endStates, const std::vector<size_t>& sampledSiteRates)
{

    // get working variables
    size_t node_index = node.getIndex();

    // get transition probabilities
    this->updateTransitionProbabilities( node_index, node.getBranchLength() );

    const AbstractHomologousDiscreteCharacterData& d = this->getValue();
    const HomologousDiscreteCharacterData<charType>& dd = static_cast<const HomologousDiscreteCharacterData<charType>& >( d );
    const DiscreteTaxonData<charType>& td = dd.getTaxonData( node.getName() );

    // ideally sample ambiguous tip states given the underlying process and ancestral state
    // for now, always sample the clamped character
    std::vector<double> p(this->num_chars, 0.0);
    for (size_t i = 0; i < this->num_sites; i++)
    {
        charType c = td.getCharacter(i);
        endStates[node_index][i] = c;
    }

    // no further recursion

}

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::fillLikelihoodVector(const TopologyNode &node, size_t node_index)
{

    // check for recomputation
    if ( dirty_nodes[node_index] == true )
    {
        // mark as computed
        dirty_nodes[node_index] = false;

        if ( node.isTip() == true )
        {
            // this is a tip node
            // compute the likelihood for the tip and we are done
            computeTipLikelihood(node, node_index);

            // rescale likelihood vector
            scale(node_index);
        }
        else
        {
            // this is an internal node
            const TopologyNode     &left        = node.getChild(0);
            size_t                  left_index  = left.getIndex();
            fillLikelihoodVector( left, left_index );
            const TopologyNode     &right       = node.getChild(1);
            size_t                  right_index = right.getIndex();
            fillLikelihoodVector( right, right_index );

            // now compute the likelihoods of this internal node
            computeInternalNodeLikelihood(node,node_index,left_index,right_index);

            // rescale likelihood vector
            scale(node_index,left_index,right_index);
        }

    }

}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::fireTreeChangeEvent( const RevBayesCore::TopologyNode &n, const unsigned& m )
{

    // call a recursive flagging of all node above (closer to the root) and including this node
    recursivelyFlagNodeDirty( n );

}


template<class charType>
std::vector<size_t> RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::getIncludedSiteIndices( void )
{
    // create a vector with the correct site indices
    // some of the sites may have been excluded
    std::vector<size_t> siteIndices;
    size_t siteIndex = 0;
    for (size_t i = 0; i < num_sites; ++i)
    {
        while ( this->value->isCharacterExcluded(siteIndex) )
        {
            siteIndex++;
            if ( siteIndex >= this->value->getNumberOfCharacters()  )
            {
                throw RbException( "The character matrix cannot set to this variable because it does not have enough included characters." );
            }
        }

        siteIndices.push_back(siteIndex);
        siteIndex++;
    }

    // test if there were additional sites that we did not use
    while ( siteIndex < this->value->getNumberOfCharacters() )
    {
        if ( !this->value->isCharacterExcluded(siteIndex)  )
        {
            throw RbException( "The character matrix cannot set to this variable because it has too many included characters." );
        }
        siteIndex++;
    }

    return siteIndices;
}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::getRootFrequencies( std::vector<std::vector<double> >& rf ) const
{
    if ( root_frequencies != NULL )
    {
        std::vector<double> f = root_frequencies->getValue();
        rf.push_back( f );
    }
    else if(heterogeneous_rate_matrices !=  NULL)
    {
        if( this->branch_heterogeneous_substitution_matrices == true)
        {
            if(root_frequencies == NULL)
            {
                throw RbException("Using branch-heterogeneous rate matrices, but no root frequencies have been specified");
            }

            std::vector<double> f = root_frequencies->getValue();
            rf.push_back( f );
        }
        else
        {
            for(size_t matrix = 0; matrix < this->num_matrices; matrix++)
            {
                const RateMatrix *rm = dynamic_cast<const RateMatrix *>(&heterogeneous_rate_matrices->getValue()[matrix]);
                if ( rm != NULL )
                {
                    rf.push_back( rm->getStationaryFrequencies() );
                }
                else
                {
                    throw RbException("If you want to use RateGenerators that are not RateMatrices then you need to specify the root frequencies directly.");
                }
            }
        }
    }
    else if(homogeneous_rate_matrix != NULL)
    {
        const RateMatrix *rm = dynamic_cast<const RateMatrix *>(&homogeneous_rate_matrix->getValue());
        if ( rm != NULL )
        {
            rf.push_back( rm->getStationaryFrequencies() );
        }
        else
        {
            throw RbException("If you want to use RateGenerators that are not RateMatrices then you need to specify the root frequencies directly.");
        }

    }
    else
    {
        rf.push_back( std::vector<double>(num_chars, 1.0/num_chars) );
    }
}

template<class charType>
std::vector<double> RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::getRootFrequencies( size_t mixture ) const
{
    if(mixture > this->num_site_mixtures)
    {
        throw(RbException("Site mixture index out of bounds"));
    }

    std::vector<std::vector<double> > rf;
    getRootFrequencies(rf);

    return rf[mixture % rf.size()];
}

template<class charType>
std::vector<double> RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::getMixtureProbs( void ) const
{
    std::vector<double> probs(num_site_mixtures, 1.0/num_site_mixtures);

    if ( site_matrix_probs != NULL )
    {
        std::vector<double> matrix_probs = site_matrix_probs->getValue();

        for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
        {
            // get matrix index
            size_t matrix = mixture % num_matrices;

            // multiply matrix prob and uniform site rate prob
            // TODO: allow non-uniform site rate probs
            probs[mixture] = matrix_probs[matrix] / num_site_rates;
        }
    }

    return probs;
}


template<class charType>
double RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::getPInv( void ) const
{

    if ( p_inv != NULL )
    {
        return p_inv->getValue();
    }
    else
    {
        return 0.0;
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::keepSpecialization( DagNode* affecter )
{

    // reset flags for likelihood computation
    touched = false;

    // reset the ln probability
    this->storedLnProb = this->lnProb;

    // reset all flags
    for (std::vector<bool>::iterator it = this->dirty_nodes.begin(); it != this->dirty_nodes.end(); ++it)
    {
        (*it) = false;
    }

    for (std::vector<bool>::iterator it = this->changed_nodes.begin(); it != this->changed_nodes.end(); ++it)
    {
        (*it) = false;
    }

}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::recursivelyFlagNodeDirty( const RevBayesCore::TopologyNode &n ) {

    // we need to flag this node and all ancestral nodes for recomputation
    size_t index = n.getIndex();

    // if this node is already dirty, the also all the ancestral nodes must have been flagged as dirty
    if ( dirty_nodes[index] == false )
    {
        // the root doesn't have an ancestor
        if ( !n.isRoot() )
        {
            recursivelyFlagNodeDirty( n.getParent() );
        }

        // set the flag
        dirty_nodes[index] = true;

        // if we previously haven't touched this node, then we need to change the active likelihood pointer
        if ( changed_nodes[index] == false )
        {
            activeLikelihood[index] = (activeLikelihood[index] == 0 ? 1 : 0);
            changed_nodes[index] = true;
        }

    }

}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::recursiveMarginalLikelihoodComputation( size_t node_index )
{

    const TopologyNode &node = tau->getValue().getNode( node_index );

    for ( size_t i=0; i<node.getNumberOfChildren(); ++i )
    {
        const TopologyNode &child = node.getChild(i);

        if ( child.isTip() == false )
        {
            size_t childIndex = child.getIndex();
            computeMarginalNodeLikelihood( childIndex, node_index );
            recursiveMarginalLikelihoodComputation( childIndex );
        }

    }
}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::redrawValue( void )
{

    bool do_mask = this->dag_node != NULL && this->dag_node->isClamped();
    std::vector<std::vector<bool> > mask_gap        = std::vector<std::vector<bool> >(tau->getValue().getNumberOfTips(), std::vector<bool>());
    std::vector<std::vector<bool> > mask_missing    = std::vector<std::vector<bool> >(tau->getValue().getNumberOfTips(), std::vector<bool>());
    // we cannot use the stored gap matrix because it uses the pattern compression
    // therefore we create our own mask
    if ( do_mask == true )
    {
        std::vector<size_t> site_indices = getIncludedSiteIndices();

        // set the gap states as in the clamped data
        for (size_t i = 0; i < tau->getValue().getNumberOfTips(); ++i)
        {
            // create a temporary variable for the taxon
            std::vector<bool> taxon_mask_gap        = std::vector<bool>(num_sites,false);
            std::vector<bool> taxon_mask_missing    = std::vector<bool>(num_sites,false);

            const std::string &taxon_name = tau->getValue().getNode( i ).getName();
            AbstractDiscreteTaxonData& taxon = value->getTaxonData( taxon_name );

            for ( size_t site=0; site<site_indices.size(); ++site)
            {
                taxon_mask_gap[site]        = taxon.getCharacter( site_indices[site] ).isGapState();
                taxon_mask_missing[site]    = taxon.getCharacter( site_indices[site] ).isMissingState();
            }

            mask_gap[i]         = taxon_mask_gap;
            mask_missing[i]     = taxon_mask_missing;

        }

    }

    // delete the old value first
    delete this->value;

    // create a new character data object
    this->value = new HomologousDiscreteCharacterData<charType>();

    // create a vector of taxon data
    std::vector< DiscreteTaxonData<charType> > taxa = std::vector< DiscreteTaxonData< charType > >( num_nodes, DiscreteTaxonData<charType>( Taxon("") ) );

    // first, simulate the per site rates
    RandomNumberGenerator* rng = GLOBAL_RNG;
    std::vector<size_t> perSiteMixtures = std::vector<size_t>(num_sites,0);
    std::vector<bool> inv = std::vector<bool>(num_sites,false);
    double prob_invariant = getPInv();
    for ( size_t i = 0; i < num_sites; ++i )
    {
        // draw if this site is invariant
        double u = rng->uniform01();
        if ( u < prob_invariant )
        {
            // this site is invariant
            inv[i] = true;

        }
        else if ( num_site_mixtures  > 1 )
        {
            // draw the rate for this site
            u = rng->uniform01();
            size_t mixtureIndex = 0;

            std::vector<double> mixtureProbs = getMixtureProbs();

            std::vector< double >::const_iterator freq = mixtureProbs.begin();
            while ( true )
            {
                u -= *freq;

                if ( u > 0.0 )
                {
                    ++mixtureIndex;
                    ++freq;
                }
                else
                {
                    break;
                }
            }

            perSiteMixtures[i] = mixtureIndex;
        }
        else
        {
            // there is only a single site rate so this is 1.0
            perSiteMixtures[i] = 0;

        }

    }

    std::vector<std::vector<double> > freqs;    getRootFrequencies(freqs);
    // simulate the root sequence
    DiscreteTaxonData< charType > &root = taxa[ tau->getValue().getRoot().getIndex() ];
    for ( size_t i = 0; i < num_sites; ++i )
    {
        const std::vector< double > &stationary_freqs = freqs[perSiteMixtures[i] % freqs.size()];

        // create the character
        charType c = charType( num_chars );
        c.setToFirstState();
        // draw the state
        double u = rng->uniform01();
        std::vector< double >::const_iterator freq = stationary_freqs.begin();
        while ( true )
        {
            u -= *freq;

            if ( u > 0.0 )
            {
                ++c;
                ++freq;
            }
            else
            {
                break;
            }

        }

        // add the character to the sequence
        root.addCharacter( c );
    }
    // recursively simulate the sequences
    root.setTaxon( Taxon("Root") );

    // recursively simulate the sequences
    simulate( tau->getValue().getRoot(), taxa, inv, perSiteMixtures );

    // add the taxon data to the character data
//    for (size_t i = 0; i < tau->getValue().getNumberOfNodes(); ++i)
    for (size_t i = 0; i < tau->getValue().getNumberOfTips(); ++i)
    {
        this->value->addTaxonData( taxa[i] );
    }

    if ( do_mask == true )
    {
        // set the gap states as in the clamped data
        for (size_t i = 0; i < tau->getValue().getNumberOfTips(); ++i)
        {
            const std::string &taxon_name = tau->getValue().getNode( i ).getName();
            AbstractDiscreteTaxonData& taxon = value->getTaxonData( taxon_name );

            for ( size_t site=0; site<num_sites; ++site)
            {
                DiscreteCharacterState &c = taxon.getCharacter(site);
                if ( mask_gap[i][site] == true )
                {
                    c.setGapState( true );
                }
                if ( mask_missing[i][site] == true )
                {
                    c.setMissingState( true );
                }
            }

        }

    }

    // compress the data and initialize internal variables
    compress();

    for (std::vector<bool>::iterator it = dirty_nodes.begin(); it != dirty_nodes.end(); ++it)
    {
        (*it) = true;
    }

    // flip the active likelihood pointers
    for (size_t index = 0; index < changed_nodes.size(); ++index)
    {
        if ( changed_nodes[index] == false )
        {
            activeLikelihood[index] = (activeLikelihood[index] == 0 ? 1 : 0);
            changed_nodes[index] = true;
        }
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::reInitialized( void )
{

    // we need to recompress because the tree may have changed
    compress();
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::resizeLikelihoodVectors( void )
{
    if (this->branch_heterogeneous_substitution_matrices == false)
    {
        this->num_site_mixtures = this->num_site_rates * this->num_matrices;
    }
    else
    {
        this->num_site_mixtures = this->num_site_rates;
    }

    // set the offsets for easier iteration through the likelihood vector
    siteOffset                  =  num_chars;
    mixtureOffset               =  pattern_block_size*siteOffset;
    nodeOffset                  =  num_site_mixtures*mixtureOffset;
    activeLikelihoodOffset      =  num_nodes*nodeOffset;

    // only do this if we are in MCMC mode. This will safe memory
    if ( inMcmcMode == true )
    {

        // we resize the partial likelihood vectors to the new dimensions
        delete [] partialLikelihoods;

        partialLikelihoods = new double[2*activeLikelihoodOffset];

        // reinitialize likelihood vectors
        for (size_t i = 0; i < 2*activeLikelihoodOffset; i++)
        {
            partialLikelihoods[i] = 0.0;
        }

    }

    if ( useMarginalLikelihoods == true )
    {
        // we resize the partial likelihood vectors to the new dimensions
        delete [] marginalLikelihoods;

        marginalLikelihoods = new double[activeLikelihoodOffset];

        // reinitialize likelihood vectors
        for (size_t i = 0; i < activeLikelihoodOffset; i++)
        {
            marginalLikelihoods[i] = 0.0;
        }

    }

    perNodeSiteLogScalingFactors = std::vector<std::vector< std::vector<double> > >(2, std::vector<std::vector<double> >(num_nodes, std::vector<double>(pattern_block_size, 0.0) ) );

    transition_prob_matrices = std::vector<TransitionProbabilityMatrix>(num_site_mixtures, TransitionProbabilityMatrix(num_chars) );

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::restoreSpecialization( DagNode* affecter )
{

    // reset flags for likelihood computation
    touched = false;

    // reset the ln probability
    this->lnProb = this->storedLnProb;

    // reset the flags
    for (std::vector<bool>::iterator it = dirty_nodes.begin(); it != dirty_nodes.end(); ++it)
    {
        (*it) = false;
    }

    // restore the active likelihoods vector
    for (size_t index = 0; index < changed_nodes.size(); ++index)
    {
        // we have to restore, that means if we have changed the active likelihood vector
        // then we need to revert this change
        if ( changed_nodes[index] == true )
        {
            activeLikelihood[index] = (activeLikelihood[index] == 0 ? 1 : 0);
        }

        // set all flags to false
        changed_nodes[index] = false;
    }

}

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::scale( size_t node_index)
{

    double* p_node = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;

    if ( RbSettings::userSettings().getUseScaling() == true && node_index % RbSettings::userSettings().getScalingDensity() == 0 )
    {
        // iterate over all mixture categories
        for (size_t site = 0; site < this->pattern_block_size ; ++site)
        {

            // the max probability
            double max = 0.0;

            // compute the per site probabilities
            for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
            {
                // get the pointers to the likelihood for this mixture category
                size_t offset = mixture*this->mixtureOffset + site*this->siteOffset;

                double*          p_site_mixture          = p_node + offset;

                for ( size_t i=0; i<this->num_chars; ++i)
                {
                    if ( p_site_mixture[i] > max )
                    {
                        max = p_site_mixture[i];
                    }
                }

            }

            this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] = -log(max);


            // compute the per site probabilities
            for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
            {
                // get the pointers to the likelihood for this mixture category
                size_t offset = mixture*this->mixtureOffset + site*this->siteOffset;

                double*          p_site_mixture          = p_node + offset;

                for ( size_t i=0; i<this->num_chars; ++i)
                {
                    p_site_mixture[i] /= max;
                }

            }

        }
    }
    else if ( RbSettings::userSettings().getUseScaling() == true )
    {
        // iterate over all mixture categories
        for (size_t site = 0; site < this->pattern_block_size ; ++site)
        {
            this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] = 0;
        }

    }
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::scale( size_t node_index, size_t left, size_t right )
{

    double* p_node = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;

    if ( RbSettings::userSettings().getUseScaling() == true && node_index % RbSettings::userSettings().getScalingDensity() == 0 )
    {
        // iterate over all mixture categories
        for (size_t site = 0; site < this->pattern_block_size ; ++site)
        {

            // the max probability
            double max = 0.0;

            // compute the per site probabilities
            for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
            {
                // get the pointers to the likelihood for this mixture category
                size_t offset = mixture*this->mixtureOffset + site*this->siteOffset;

                double*          p_site_mixture          = p_node + offset;

                for ( size_t i=0; i<this->num_chars; ++i)
                {
                    if ( p_site_mixture[i] > max )
                    {
                        max = p_site_mixture[i];
                    }
                }

            }

            this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] = this->perNodeSiteLogScalingFactors[this->activeLikelihood[left]][left][site] + this->perNodeSiteLogScalingFactors[this->activeLikelihood[right]][right][site] - log(max);


            // compute the per site probabilities
            for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
            {
                // get the pointers to the likelihood for this mixture category
                size_t offset = mixture*this->mixtureOffset + site*this->siteOffset;

                double*          p_site_mixture          = p_node + offset;

                for ( size_t i=0; i<this->num_chars; ++i)
                {
                    p_site_mixture[i] /= max;
                }

            }

        }
    }
    else if ( RbSettings::userSettings().getUseScaling() == true )
    {
        // iterate over all mixture categories
        for (size_t site = 0; site < this->pattern_block_size ; ++site)
        {
            this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] = this->perNodeSiteLogScalingFactors[this->activeLikelihood[left]][left][site] + this->perNodeSiteLogScalingFactors[this->activeLikelihood[right]][right][site];
        }

    }
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::scale( size_t node_index, size_t left, size_t right, size_t middle )
{

    double* p_node   = this->partialLikelihoods + this->activeLikelihood[node_index]*this->activeLikelihoodOffset + node_index*this->nodeOffset;

    if ( RbSettings::userSettings().getUseScaling() == true && node_index % RbSettings::userSettings().getScalingDensity() == 0 )
    {
        // iterate over all mixture categories
        for (size_t site = 0; site < this->pattern_block_size ; ++site)
        {

            // the max probability
            double max = 0.0;

            // compute the per site probabilities
            for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
            {
                // get the pointers to the likelihood for this mixture category
                size_t offset = mixture*this->mixtureOffset + site*this->siteOffset;

                double*          p_site_mixture          = p_node + offset;

                for ( size_t i=0; i<this->num_chars; ++i)
                {
                    if ( p_site_mixture[i] > max )
                    {
                        max = p_site_mixture[i];
                    }
                }

            }

            this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] = this->perNodeSiteLogScalingFactors[this->activeLikelihood[left]][left][site] + this->perNodeSiteLogScalingFactors[this->activeLikelihood[right]][right][site] + this->perNodeSiteLogScalingFactors[this->activeLikelihood[middle]][middle][site] - log(max);


            // compute the per site probabilities
            for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
            {
                // get the pointers to the likelihood for this mixture category
                size_t offset = mixture*this->mixtureOffset + site*this->siteOffset;

                double*          p_site_mixture          = p_node + offset;

                for ( size_t i=0; i<this->num_chars; ++i)
                {
                    p_site_mixture[i] /= max;
                }

            }

        }
    }
    else if ( RbSettings::userSettings().getUseScaling() == true )
    {
        // iterate over all mixture categories
        for (size_t site = 0; site < this->pattern_block_size ; ++site)
        {
            this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] = this->perNodeSiteLogScalingFactors[this->activeLikelihood[left]][left][site] + this->perNodeSiteLogScalingFactors[this->activeLikelihood[right]][right][site] + this->perNodeSiteLogScalingFactors[this->activeLikelihood[middle]][middle][site];
        }

    }
}


/**
 * Set the active PID of this specific distribution object.
 */
template <class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setActivePIDSpecialized(size_t a, size_t n)
{

    // we need to recompress the data
    this->compress();
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setValue(AbstractHomologousDiscreteCharacterData *v, bool force)
{

    if (v->getMaxObservedStateIndex() > this->num_chars - 1)
    {
        // We might use different sized matrices for different partitions depending on the observed number of states.
        std::stringstream ss;
        ss << "The number of observed states (" << v->getMaxObservedStateIndex() + 1 << ") is greater than the dimension of the Q matrix (" << this->num_chars << ")" << std::endl;
        throw RbException(ss.str());
    }

    // delegate to the parent class
    TypedDistribution< AbstractHomologousDiscreteCharacterData >::setValue(v, force);

    // reset the number of sites
    this->num_sites = v->getNumberOfIncludedCharacters();

	site_pattern.clear();
	site_pattern.resize(num_sites);

    // now compress the data and resize the likelihood vectors
    this->compress();

    // now we also set the template state
    template_state = charType( static_cast<const charType&>( this->value->getTaxonData(0).getCharacter(0) ) );
    template_state.setToFirstState();
    template_state.setGapState( false );
    template_state.setMissingState( false );

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::simulate( const TopologyNode &node, std::vector< DiscreteTaxonData< charType > > &taxa, const std::vector<bool> &invariant, const std::vector<size_t> &perSiteMixtures)
{

    // get the children of the node
    const std::vector<TopologyNode*>& children = node.getChildren();

    // get the sequence of this node
    size_t node_index = node.getIndex();
    const DiscreteTaxonData< charType > &parent = taxa[ node_index ];

    // simulate the sequence for each child
    RandomNumberGenerator* rng = GLOBAL_RNG;
    for (std::vector< TopologyNode* >::const_iterator it = children.begin(); it != children.end(); ++it)
    {
        const TopologyNode &child = *(*it);

        // update the transition probability matrix
        updateTransitionProbabilities( child.getIndex(), child.getBranchLength() );

        DiscreteTaxonData< charType > &taxon = taxa[ child.getIndex() ];
        for ( size_t i = 0; i < num_sites; ++i )
        {

            if ( invariant[i] == true )
            {

                // add the character to the sequence
                taxon.addCharacter( parent.getCharacter( i ) );
            }
            else
            {
                // get the ancestral character for this site
                unsigned long parentState = parent.getCharacter( i ).getStateIndex();

                double *freqs = transition_prob_matrices[ perSiteMixtures[i] ][ parentState ];

                // create the character
                charType c = charType( num_chars );
                c.setToFirstState();
                // draw the state
                double u = rng->uniform01();
                size_t stateIndex = 0;
                while ( true )
                {
                    u -= *freqs;
                    ++stateIndex;

                    if ( u > 0.0 && stateIndex < this->num_chars)
                    {
                        ++c;
                        ++freqs;
                    }
                    else
                    {
                        break;
                    }

                }

                // add the character to the sequence
                taxon.addCharacter( c );
            }

        }

        if ( child.isTip() )
        {
            taxon.setTaxon( child.getTaxon() );
        }
        else
        {
            // recursively simulate the sequences
            std::stringstream ss;
            ss << "Node" << child.getIndex();
            taxon.setTaxon( Taxon(ss.str()) );
            simulate( child, taxa, invariant, perSiteMixtures );
        }

    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setClockRate(const TypedDagNode< double > *r)
{

    // remove the old parameter first
    if ( homogeneous_clock_rate != NULL )
    {
        this->removeParameter( homogeneous_clock_rate );
        homogeneous_clock_rate = NULL;
    }
    else // heterogeneousClockRate != NULL
    {
        this->removeParameter( heterogeneous_clock_rates );
        heterogeneous_clock_rates = NULL;
    }

    // set the value
    branch_heterogeneous_clock_rates = false;
    homogeneous_clock_rate = r;

    // add the new parameter
    this->addParameter( homogeneous_clock_rate );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }

}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setClockRate(const TypedDagNode< RbVector< double > > *r)
{

    // remove the old parameter first
    if ( homogeneous_clock_rate != NULL )
    {
        this->removeParameter( homogeneous_clock_rate );
        homogeneous_clock_rate = NULL;
    }
    else // heterogeneousClockRate != NULL
    {
        this->removeParameter( heterogeneous_clock_rates );
        heterogeneous_clock_rates = NULL;
    }

    // set the value
    branch_heterogeneous_clock_rates = true;
    heterogeneous_clock_rates = r;

    // add the new parameter
    this->addParameter( heterogeneous_clock_rates );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }

}


/**
 * Change the likelihood computation to or from MCMC mode.
 */

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setMcmcMode(bool tf)
{

    // free old memory
    if ( inMcmcMode == true )
    {
        delete [] partialLikelihoods;
        partialLikelihoods = NULL;
    }

    // set our internal flag
    inMcmcMode = tf;

    if ( inMcmcMode == true )
    {
        resizeLikelihoodVectors();
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setPInv(const TypedDagNode< double > *r)
{

    // remove the old parameter first
    if ( p_inv != NULL )
    {
        this->removeParameter( p_inv );
        p_inv = NULL;
    }

    // set the value
    p_inv = r;

    // add the new parameter
    this->addParameter( p_inv );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setRateMatrix(const TypedDagNode< RateGenerator > *rm) {

    // remove the old parameter first
    if ( homogeneous_rate_matrix != NULL )
    {
        this->removeParameter( homogeneous_rate_matrix );
        homogeneous_rate_matrix = NULL;
    }
    else // heterogeneousRateMatrix != NULL
    {
        this->removeParameter( heterogeneous_rate_matrices );
        heterogeneous_rate_matrices = NULL;
    }

    // set the value
    homogeneous_rate_matrix = rm;
    num_matrices = 1;

    this->resizeLikelihoodVectors();

    if(rm != NULL && rm->getValue().size() != this->num_chars)
    {
        std::stringstream ss;
        ss << "Rate generator dimensions (" << rm->getValue().size() << " do not match the number of character states (" << this->num_chars << ")";
        throw(RbException(ss.str()));
    }

    // add the new parameter
    this->addParameter( homogeneous_rate_matrix );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setRateMatrix(const TypedDagNode< RbVector< RateGenerator > > *rm) {

    // remove the old parameter first
    if ( homogeneous_rate_matrix != NULL )
    {
        this->removeParameter( homogeneous_rate_matrix );
        homogeneous_rate_matrix = NULL;
    }
    else // heterogeneousRateMatrix != NULL
    {
        this->removeParameter( heterogeneous_rate_matrices );
        heterogeneous_rate_matrices = NULL;
    }

    // set the value
    heterogeneous_rate_matrices = rm;
    num_matrices = rm == NULL ? 1 : rm->getValue().size();

    this->resizeLikelihoodVectors();

    if(rm != NULL && rm->getValue()[0].size() != this->num_chars)
    {
        std::stringstream ss;
        ss << "Rate generator dimensions (" << rm->getValue()[0].size() << " do not match the number of character states (" << this->num_chars << ")";
        throw(RbException(ss.str()));
    }

    // add the new parameter
    this->addParameter( heterogeneous_rate_matrices );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setRootFrequencies(const TypedDagNode< RbVector< double > > *f)
{

    // remove the old parameter first
    if ( root_frequencies != NULL )
    {
        this->removeParameter( root_frequencies );
        root_frequencies = NULL;
    }

    if ( f != NULL )
    {
        // set the value
        root_frequencies = f;
    }

    // add the new parameter
    this->addParameter( root_frequencies );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }

}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setSiteRates(const TypedDagNode< RbVector< double > > *r)
{

    // remove the old parameter first
    if ( site_rates != NULL )
    {
        this->removeParameter( site_rates );
        site_rates = NULL;
    }

    if ( r != NULL )
    {
        // set the value
        rate_variation_across_sites = true;
        site_rates = r;
        this->num_site_rates = r->getValue().size();
    }
    else
    {
        // set the value
        rate_variation_across_sites = false;
        site_rates = NULL;
        this->num_site_rates = 1;
    }

    this->resizeLikelihoodVectors();

    // add the new parameter
    this->addParameter( site_rates );

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }
}


template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setUseMarginalLikelihoods(bool tf)
{

    this->useMarginalLikelihoods = tf;
    this->resizeLikelihoodVectors();

}

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::setUseSiteMatrices(bool sm, const TypedDagNode< RbVector< double > > *s)
{

    if( sm == false && s != NULL)
    {
        throw(RbException("Provided site matrix probs but not using site matrix mixture."));
    }

    // remove the old parameter first
    if ( site_matrix_probs != NULL )
    {
        this->removeParameter( site_matrix_probs );
        site_matrix_probs = NULL;
    }

    if ( sm )
    {
        // set the value
        site_matrix_probs = s;
    }

    // add the new parameter
    this->addParameter( site_matrix_probs );

    this->branch_heterogeneous_substitution_matrices = !sm;

    this->resizeLikelihoodVectors();

    // redraw the current value
    if ( this->dag_node == NULL || this->dag_node->isClamped() == false )
    {
        this->redrawValue();
    }
}


template<class charType>
std::vector< std::vector<double> >* RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::sumMarginalLikelihoods( size_t node_index )
{

    std::vector< std::vector<double> >* per_mixture_Likelihoods = new std::vector< std::vector<double> >(this->pattern_block_size, std::vector<double>(num_chars, 0.0) );

    std::vector<double> mixture_probs = getMixtureProbs();

    // get the pointers to the partial likelihoods and the marginal likelihoods
    double*         p_node_marginal         = this->marginalLikelihoods + node_index*this->nodeOffset;

    // get pointers the likelihood for both subtrees
    double*         p_mixture_marginal          = p_node_marginal;
    // iterate over all mixture categories
    for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
    {

        // get pointers to the likelihood for this mixture category
        double*         p_site_mixture_marginal         = p_mixture_marginal;
        // iterate over all sites
        for (size_t site = 0; site < this->pattern_block_size; ++site)
        {
            // get the pointers to the likelihoods for this site and mixture category
            double*         p_site_marginal_j           = p_site_mixture_marginal;
            // iterate over all starting states
            for (size_t j=0; j<num_chars; ++j)
            {
                // add the probability of being in this state
                (*per_mixture_Likelihoods)[site][j] += *p_site_marginal_j * mixture_probs[mixture];

                // increment pointers
                ++p_site_marginal_j;
            }

            // increment the pointers to the next site
            p_site_mixture_marginal+=this->siteOffset;

        } // end-for over all sites (=patterns)

        // increment the pointers to the next mixture category
        p_mixture_marginal+=this->mixtureOffset;

    } // end-for over all mixtures (=rate categories)

    return per_mixture_Likelihoods;
}




template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::computeRootLikelihoods( std::vector<double> &rv ) const
{
    // get the root node
    const TopologyNode &root = tau->getValue().getRoot();

    // get the index of the root node
    size_t node_index = root.getIndex();

    // get the pointers to the partial likelihoods of the left and right subtree
    double*   p_node  = this->partialLikelihoods + this->activeLikelihood[node_index] * this->activeLikelihoodOffset  + node_index*this->nodeOffset;

    // create a vector for the per mixture likelihoods
    // we need this vector to sum over the different mixture likelihoods
    std::vector<double> per_mixture_Likelihoods = std::vector<double>(pattern_block_size,0.0);

    std::vector<double> site_mixture_probs = getMixtureProbs();

    // get pointer the likelihood
    double*   p_mixture     = p_node;
    // iterate over all mixture categories
    for (size_t mixture = 0; mixture < this->num_site_mixtures; ++mixture)
    {

        // get pointers to the likelihood for this mixture category
        double*   p_site_mixture     = p_mixture;
        // iterate over all sites

        for (size_t site = 0; site < pattern_block_size; ++site)
        {
            // temporary variable storing the likelihood
            double tmp = 0.0;
            // get the pointers to the likelihoods for this site and mixture category
            double* p_site_j   = p_site_mixture;
            // iterate over all starting states
            for (size_t i=0; i<num_chars; ++i)
            {
                // add the probability of starting from this state
                tmp += *p_site_j;

                // increment pointers
                ++p_site_j;
            }
            // add the likelihood for this mixture category
            per_mixture_Likelihoods[site] += tmp * site_mixture_probs[mixture];

            // increment the pointers to the next site
            p_site_mixture+=this->siteOffset;

        } // end-for over all sites (=patterns)

        // increment the pointers to the next mixture category
        p_mixture+=this->mixtureOffset;

    } // end-for over all mixtures (=rate categories)

    double prob_invariant = getPInv();
    double oneMinusPInv = 1.0 - prob_invariant;
    std::vector< size_t >::const_iterator patterns = this->pattern_counts.begin();
    if ( prob_invariant > 0.0 )
    {
        // get the mean root frequency vector
        std::vector<double> f;
        if(this->branch_heterogeneous_substitution_matrices == true)
        {
            f = this->getRootFrequencies(0);
        }
        else
        {
            std::vector<std::vector<double> > ff;
            getRootFrequencies(ff);

            std::vector<double> matrix_probs(num_matrices, 1.0/num_matrices);

            if(site_matrix_probs != NULL)
            {
                matrix_probs = site_matrix_probs->getValue();
            }

            f = std::vector<double>(ff[0].size(), 0.0);

            for(size_t matrix = 0; matrix < ff.size(); matrix++)
            {
                // get the root frequencies
                const std::vector<double> &fm = ff[matrix];

                for(size_t i = 0; i < fm.size(); i++)
                {
                    f[i] += fm[i] * matrix_probs[matrix];
                }
            }
        }

        for (size_t site = 0; site < pattern_block_size; ++site, ++patterns)
        {

            if ( RbSettings::userSettings().getUseScaling() == true )
            {

                if ( this->site_invariant[site] == true )
                {
                    rv[site] = log( prob_invariant * f[ this->invariant_site_index[site] ] * exp(this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site]) + oneMinusPInv * per_mixture_Likelihoods[site] ) * *patterns;
                }
                else
                {
                    rv[site] = log( oneMinusPInv * per_mixture_Likelihoods[site] ) * *patterns;
                }
                rv[site] -= this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] * *patterns;

            }
            else // no scaling
            {

                if ( this->site_invariant[site] == true )
                {
                    rv[site] = log( prob_invariant * f[ this->invariant_site_index[site] ]  + oneMinusPInv * per_mixture_Likelihoods[site] ) * *patterns;
                }
                else
                {
                    rv[site] = log( oneMinusPInv * per_mixture_Likelihoods[site] ) * *patterns;
                }

            }

        }

    }
    else
    {

        for (size_t site = 0; site < pattern_block_size; ++site, ++patterns)
        {
            rv[site] = log( per_mixture_Likelihoods[site] ) * *patterns;

            if ( RbSettings::userSettings().getUseScaling() == true )
            {
                rv[site] -= this->perNodeSiteLogScalingFactors[this->activeLikelihood[node_index]][node_index][site] * *patterns;
            }

        }

    }

}



template<class charType>
double RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::sumRootLikelihood( void )
{


    std::vector<double> site_likelihoods = std::vector<double>(pattern_block_size,0.0);
    computeRootLikelihoods( site_likelihoods );

    double sum_partial_probs = 0.0;

    for (size_t site = 0; site < pattern_block_size; ++site)
    {
        sum_partial_probs += site_likelihoods[site];
    }

#ifdef RB_MPI

    // we only need to send message if there is more than one process
    if ( num_processes > 1 )
    {

        // send the likelihood from the helpers to the master
        if ( process_active == false )
        {
            // send from the workers the log-likelihood to the master
            MPI::COMM_WORLD.Send(&sum_partial_probs, 1, MPI::DOUBLE, active_PID, 0);
        }

        // receive the likelihoods from the helpers
        if ( process_active == true )
        {
            for (size_t i=active_PID+1; i<active_PID+num_processes; ++i)
            {
                double tmp = 0;
                MPI::COMM_WORLD.Recv(&tmp, 1, MPI::DOUBLE, int(i), 0);
                sum_partial_probs += tmp;
            }
        }

        // now send back the combined likelihood to the helpers
        if ( process_active == true )
        {
            for (size_t i=active_PID+1; i<active_PID+num_processes; ++i)
            {
                MPI::COMM_WORLD.Send(&sum_partial_probs, 1, MPI::DOUBLE, int(i), 0);
            }
        }
        else
        {
            MPI::COMM_WORLD.Recv(&sum_partial_probs, 1, MPI::DOUBLE, active_PID, 0);
        }

    }

#endif

    return sum_partial_probs;
}



/** Swap a parameter of the distribution */
template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::swapParameterInternal(const DagNode *oldP, const DagNode *newP)
{

    if (oldP == homogeneous_clock_rate)
    {
        homogeneous_clock_rate = static_cast<const TypedDagNode< double >* >( newP );
    }
    else if (oldP == heterogeneous_clock_rates)
    {
        heterogeneous_clock_rates = static_cast<const TypedDagNode< RbVector< double > >* >( newP );
    }
    else if (oldP == homogeneous_rate_matrix)
    {
        homogeneous_rate_matrix = static_cast<const TypedDagNode< RateGenerator >* >( newP );
    }
    else if (oldP == heterogeneous_rate_matrices)
    {
        heterogeneous_rate_matrices = static_cast<const TypedDagNode< RbVector< RateGenerator > >* >( newP );
    }
    else if (oldP == root_frequencies)
    {
        root_frequencies = static_cast<const TypedDagNode< RbVector< double > >* >( newP );
    }
    else if (oldP == site_rates)
    {
        site_rates = static_cast<const TypedDagNode< RbVector< double > >* >( newP );
    }
    else if (oldP == site_rates_probs)
    {
        site_rates_probs = static_cast<const TypedDagNode< RbVector< double > >* >( newP );
    }
    else if (oldP == p_inv)
    {
        p_inv = static_cast<const TypedDagNode< double >* >( newP );
    }
    else if (oldP == tau)
    {
        tau->getValue().getTreeChangeEventHandler().removeListener( this );

        tau = static_cast<const TypedDagNode<Tree>* >( newP );

        tau->getValue().getTreeChangeEventHandler().addListener( this );

        num_nodes = tau->getValue().getNumberOfNodes();
    }

}

template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::touchSpecialization( DagNode* affecter, bool touchAll )
{

    if ( touched == false )
    {
        touched = true;
        this->storedLnProb = this->lnProb;
    }


    // if the topology wasn't the culprit for the touch, then we just flag everything as dirty
    if ( affecter == heterogeneous_clock_rates )
    {
        const std::set<size_t> &indices = heterogeneous_clock_rates->getTouchedElementIndices();

        // maybe all of them have been touched or the flags haven't been set properly
        if ( indices.size() == 0 )
        {
            // just flag everyting for recomputation
            touchAll = true;
        }
        else
        {
            const std::vector<TopologyNode *> &nodes = this->tau->getValue().getNodes();
            // flag recomputation only for the nodes
            for (std::set<size_t>::iterator it = indices.begin(); it != indices.end(); ++it)
            {
                this->recursivelyFlagNodeDirty( *nodes[*it] );
            }
        }
    }
    else if ( affecter == heterogeneous_rate_matrices && branch_heterogeneous_substitution_matrices == true)
    {
        const std::set<size_t> &indices = heterogeneous_rate_matrices->getTouchedElementIndices();

        // maybe all of them have been touched or the flags haven't been set properly
        if ( indices.size() == 0 )
        {
            // just flag everyting for recomputation
            touchAll = true;
        }
        else
        {
            const std::vector<TopologyNode *> &nodes = this->tau->getValue().getNodes();
            // flag recomputation only for the nodes
            for (std::set<size_t>::iterator it = indices.begin(); it != indices.end(); ++it)
            {
                this->recursivelyFlagNodeDirty( *nodes[*it] );
            }
        }
    }
    else if ( affecter == root_frequencies )
    {

        const TopologyNode &root = this->tau->getValue().getRoot();
        this->recursivelyFlagNodeDirty( root );
    }
    else if ( affecter != tau ) // if the topology wasn't the culprit for the touch, then we just flag everything as dirty
    {
        touchAll = true;
    }

    if ( touchAll )
    {

        for (std::vector<bool>::iterator it = dirty_nodes.begin(); it != dirty_nodes.end(); ++it)
        {
            (*it) = true;
        }

        // flip the active likelihood pointers
        for (size_t index = 0; index < changed_nodes.size(); ++index)
        {
            if ( changed_nodes[index] == false )
            {
                activeLikelihood[index] = (activeLikelihood[index] == 0 ? 1 : 0);
                changed_nodes[index] = true;
            }
        }
    }

}



template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::updateMarginalNodeLikelihoods( void )
{

    // calculate the root marginal likelihood, then start the recursive call down the tree
    this->computeMarginalRootLikelihood();

    // update the marginal likelihoods by a recursive downpass
    this->recursiveMarginalLikelihoodComputation( tau->getValue().getRoot().getIndex() );


}




template<class charType>
void RevBayesCore::AbstractPhyloCTMCSiteHomogeneous<charType>::updateTransitionProbabilities(size_t node_idx, double brlen)
{
    const TopologyNode* node = tau->getValue().getNodes()[node_idx];

    if (node->isRoot()) throw RbException("dnPhyloCTMC called updateTransitionProbabilities for the root node\n");

    // second, get the clock rate for the branch
    double rate = 1.0;
    if ( this->branch_heterogeneous_clock_rates == true )
    {
        rate = this->heterogeneous_clock_rates->getValue()[node_idx];
    }
    else if(homogeneous_clock_rate != NULL)
    {
        rate = this->homogeneous_clock_rate->getValue();
    }

    double end_age = node->getAge();

    // if the tree is not a time tree, then the age will be not a number
    if ( RbMath::isFinite(end_age) == false )
    {
        // we assume by default that the end is at time 0
        end_age = 0.0;
    }
    double start_age = end_age + node->getBranchLength();

    // first, get the rate matrix for this branch
    RateMatrix_JC jc(this->num_chars);
    const RateGenerator *rm = &jc;

    if (this->branch_heterogeneous_substitution_matrices == false )
    {
        for (size_t matrix = 0; matrix < this->num_matrices; ++matrix)
        {
            if ( this->heterogeneous_rate_matrices != NULL )
            {
                rm = &this->heterogeneous_rate_matrices->getValue()[matrix];
            }
            else if( this->homogeneous_rate_matrix != NULL )
            {
                rm = &this->homogeneous_rate_matrix->getValue();
            }

            for (size_t j = 0; j < this->num_site_rates; ++j)
            {
                double r = 1.0;
                if( this->rate_variation_across_sites == true )
                {
                    r = this->site_rates->getValue()[j];
                }

                rm->calculateTransitionProbabilities( start_age, end_age,  rate * r, this->transition_prob_matrices[j*this->num_matrices + matrix] );
            }
        }
    }
    else
    {
        if ( this->heterogeneous_rate_matrices != NULL )
        {
            rm = &this->heterogeneous_rate_matrices->getValue()[node_idx];
        }
        else if( this->homogeneous_rate_matrix != NULL )
        {
            rm = &this->homogeneous_rate_matrix->getValue();
        }

        for (size_t j = 0; j < this->num_site_rates; ++j)
        {
            double r = 1.0;
            if( this->rate_variation_across_sites == true )
            {
                r = this->site_rates->getValue()[j];
            }

            rm->calculateTransitionProbabilities( start_age, end_age,  rate * r, this->transition_prob_matrices[j] );
        }
    }
}

#endif
